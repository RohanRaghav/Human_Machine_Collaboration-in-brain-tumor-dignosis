{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 2236708,
          "sourceType": "datasetVersion",
          "datasetId": 1343913
        }
      ],
      "dockerImageVersionId": 30120,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Human-Machine Collaboration brain tumor dignosis",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanRaghav/Human_Machine_Collaboration-in-brain-tumor-dignosis/blob/main/Human_Machine_Collaboration_brain_tumor_dignosis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'brian-tumor-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1343913%2F2236708%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240701%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240701T064401Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D57093efa8c935ad53f3a311fba8bf7965abd32ea738637bd202e61d443b91de8e2a84070eb943a78b501339328279103bb792d841f40c532b48b346baa15a0cb00767535066523056101ce70607d06e9889da5f219f1f05bd935aa7daf98be4cac4bd9102a8f0742d0bead5d830d6c1a733da131ce05eb5c2c0cb215ce8fb02d4dc5f987fab01a4b380e8cbb9671e2e251561af80c8b876ba697e89954b9e36e3abde8492e7a61d00bddb23a6fa695abb3f5b5a3020fa96d4a7151e5adb4bec485c335bd9e60138767a5caadb97999f3882288fb746f003f2052da1c57f183f4d942ef48ab3a59e50bbf44a2370c589225b5905282d769e816316f2e3cf1c9dd'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "YEaa_Hs2CVQH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-24T05:51:56.165664Z",
          "iopub.execute_input": "2024-04-24T05:51:56.166093Z",
          "iopub.status.idle": "2024-04-24T05:52:00.778492Z",
          "shell.execute_reply.started": "2024-04-24T05:51:56.166008Z",
          "shell.execute_reply": "2024-04-24T05:52:00.771624Z"
        },
        "trusted": true,
        "id": "MXkOEb9CCVQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:00.779777Z",
          "iopub.execute_input": "2024-04-24T05:52:00.780065Z",
          "iopub.status.idle": "2024-04-24T05:52:06.68687Z",
          "shell.execute_reply.started": "2024-04-24T05:52:00.780037Z",
          "shell.execute_reply": "2024-04-24T05:52:06.686076Z"
        },
        "trusted": true,
        "id": "W0MS6whgCVQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = ImageDataGenerator(rescale=1./255,validation_split = 0.2,zoom_range=(0.99,0.99),dtype=tf.float32)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:06.688748Z",
          "iopub.execute_input": "2024-04-24T05:52:06.68907Z",
          "iopub.status.idle": "2024-04-24T05:52:06.693753Z",
          "shell.execute_reply.started": "2024-04-24T05:52:06.68904Z",
          "shell.execute_reply": "2024-04-24T05:52:06.692714Z"
        },
        "trusted": true,
        "id": "sogWQSIPCVQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                               target_size = (150,150),\n",
        "                               batch_size = 256,\n",
        "                               class_mode = \"binary\",\n",
        "                               color_mode = \"rgb\",\n",
        "                               shuffle = True,\n",
        "                               seed = 123,\n",
        "                               subset = \"training\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:06.695327Z",
          "iopub.execute_input": "2024-04-24T05:52:06.695606Z",
          "iopub.status.idle": "2024-04-24T05:52:07.499511Z",
          "shell.execute_reply.started": "2024-04-24T05:52:06.69558Z",
          "shell.execute_reply": "2024-04-24T05:52:07.498591Z"
        },
        "trusted": true,
        "id": "la39U7S9CVQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                               target_size = (150,150),\n",
        "                               batch_size = 8,\n",
        "                               class_mode = \"binary\",\n",
        "                               color_mode = \"rgb\",\n",
        "                               shuffle = True,\n",
        "                               seed = 123,\n",
        "                               subset = \"validation\")\n",
        "classes = val.class_indices"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:07.500601Z",
          "iopub.execute_input": "2024-04-24T05:52:07.50094Z",
          "iopub.status.idle": "2024-04-24T05:52:07.610369Z",
          "shell.execute_reply.started": "2024-04-24T05:52:07.500903Z",
          "shell.execute_reply": "2024-04-24T05:52:07.609357Z"
        },
        "trusted": true,
        "id": "owZUfKdxCVQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With grayscale as color mode we get high spikes in validation loss in training and substantially lower accuracy compared with a dataset with rgb color mode."
      ],
      "metadata": {
        "id": "YmD8DVaBCVQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:07.611574Z",
          "iopub.execute_input": "2024-04-24T05:52:07.611892Z",
          "iopub.status.idle": "2024-04-24T05:52:07.620001Z",
          "shell.execute_reply.started": "2024-04-24T05:52:07.611862Z",
          "shell.execute_reply": "2024-04-24T05:52:07.619046Z"
        },
        "trusted": true,
        "id": "meclV_gzCVQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:07.621343Z",
          "iopub.execute_input": "2024-04-24T05:52:07.621689Z",
          "iopub.status.idle": "2024-04-24T05:52:08.24582Z",
          "shell.execute_reply.started": "2024-04-24T05:52:07.621657Z",
          "shell.execute_reply": "2024-04-24T05:52:08.245021Z"
        },
        "trusted": true,
        "id": "4jyJAV8DCVQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class distribution in training dataset"
      ],
      "metadata": {
        "id": "F1dHVhy-CVQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t=0\n",
        "h=0\n",
        "for i in range(15):\n",
        "    a, b = next(train)\n",
        "    for j in b:\n",
        "        if j == 1:\n",
        "            h+=1\n",
        "        else:t+=1\n",
        "\n",
        "sns.barplot(x=['tumor','healty'],y=[t,h])\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:08.248456Z",
          "iopub.execute_input": "2024-04-24T05:52:08.248736Z",
          "iopub.status.idle": "2024-04-24T05:52:46.073706Z",
          "shell.execute_reply.started": "2024-04-24T05:52:08.248708Z",
          "shell.execute_reply": "2024-04-24T05:52:46.072836Z"
        },
        "trusted": true,
        "id": "Mc7YaatcCVQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "batch = next(train)\n",
        "\n",
        "plt.imshow(batch[0][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:46.075478Z",
          "iopub.execute_input": "2024-04-24T05:52:46.07575Z",
          "iopub.status.idle": "2024-04-24T05:52:48.163496Z",
          "shell.execute_reply.started": "2024-04-24T05:52:46.075722Z",
          "shell.execute_reply": "2024-04-24T05:52:48.162291Z"
        },
        "trusted": true,
        "id": "O1c2EszsCVQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple cnn"
      ],
      "metadata": {
        "id": "sVE8xLtBCVQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, LeakyReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:48.165233Z",
          "iopub.execute_input": "2024-04-24T05:52:48.165655Z",
          "iopub.status.idle": "2024-04-24T05:52:48.173089Z",
          "shell.execute_reply.started": "2024-04-24T05:52:48.165607Z",
          "shell.execute_reply": "2024-04-24T05:52:48.171915Z"
        },
        "trusted": true,
        "id": "ue2xwfZGCVQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(150,150,3)))\n",
        "model.add(Conv2D(filters=32,kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(filters=64,kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(rate=0.3))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(optimizer=Adam(0.001),loss = BinaryCrossentropy(),metrics=['accuracy'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:48.174606Z",
          "iopub.execute_input": "2024-04-24T05:52:48.174967Z",
          "iopub.status.idle": "2024-04-24T05:52:51.20802Z",
          "shell.execute_reply.started": "2024-04-24T05:52:48.174932Z",
          "shell.execute_reply": "2024-04-24T05:52:51.206977Z"
        },
        "trusted": true,
        "id": "H-5nMfgeCVQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:51.209352Z",
          "iopub.execute_input": "2024-04-24T05:52:51.209646Z",
          "iopub.status.idle": "2024-04-24T05:52:51.220038Z",
          "shell.execute_reply.started": "2024-04-24T05:52:51.209618Z",
          "shell.execute_reply": "2024-04-24T05:52:51.219244Z"
        },
        "trusted": true,
        "id": "lohEr7GECVQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model plot"
      ],
      "metadata": {
        "id": "-nlYhlI5CVQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model.png', show_shapes=True,\n",
        "    show_layer_names=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:51.221323Z",
          "iopub.execute_input": "2024-04-24T05:52:51.221629Z",
          "iopub.status.idle": "2024-04-24T05:52:52.046797Z",
          "shell.execute_reply.started": "2024-04-24T05:52:51.221602Z",
          "shell.execute_reply": "2024-04-24T05:52:52.045802Z"
        },
        "trusted": true,
        "id": "Dg9MO2yECVQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import utils, callbacks\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
        "                                        patience=5, restore_best_weights = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:52.048594Z",
          "iopub.execute_input": "2024-04-24T05:52:52.049117Z",
          "iopub.status.idle": "2024-04-24T05:52:52.054349Z",
          "shell.execute_reply.started": "2024-04-24T05:52:52.049073Z",
          "shell.execute_reply": "2024-04-24T05:52:52.053485Z"
        },
        "trusted": true,
        "id": "v49wQldnCVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have defined and trained your model (named 'model') before this code snippet\n",
        "history = model.fit(train, verbose=1, callbacks=[earlystopping], epochs=20, validation_data=val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = history.history['val_accuracy'][-1]\n",
        "print(\"Validation Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T05:52:52.05543Z",
          "iopub.execute_input": "2024-04-24T05:52:52.055734Z",
          "iopub.status.idle": "2024-04-24T06:05:02.535013Z",
          "shell.execute_reply.started": "2024-04-24T05:52:52.055704Z",
          "shell.execute_reply": "2024-04-24T06:05:02.533847Z"
        },
        "trusted": true,
        "id": "mkpWLaXFCVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/kaggle/working/model_cnn.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:02.536565Z",
          "iopub.execute_input": "2024-04-24T06:05:02.536914Z",
          "iopub.status.idle": "2024-04-24T06:05:02.855192Z",
          "shell.execute_reply.started": "2024-04-24T06:05:02.536878Z",
          "shell.execute_reply": "2024-04-24T06:05:02.854404Z"
        },
        "trusted": true,
        "id": "qvPApYhICVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting accuracy"
      ],
      "metadata": {
        "id": "XwIY5s9pCVQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:02.8565Z",
          "iopub.execute_input": "2024-04-24T06:05:02.856917Z",
          "iopub.status.idle": "2024-04-24T06:05:03.05077Z",
          "shell.execute_reply.started": "2024-04-24T06:05:02.856873Z",
          "shell.execute_reply": "2024-04-24T06:05:03.049923Z"
        },
        "trusted": true,
        "id": "0iOPFCTXCVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hZ6LTYbUCVQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting loss"
      ],
      "metadata": {
        "id": "vCXcE6fuCVQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:03.051876Z",
          "iopub.execute_input": "2024-04-24T06:05:03.052177Z",
          "iopub.status.idle": "2024-04-24T06:05:03.228321Z",
          "shell.execute_reply.started": "2024-04-24T06:05:03.052148Z",
          "shell.execute_reply": "2024-04-24T06:05:03.22753Z"
        },
        "trusted": true,
        "id": "3vvhsN3UCVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer\n",
        "from keras.models import Sequential\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Data preparation\n",
        "gen = ImageDataGenerator(rescale=1./255, validation_split=0.2, zoom_range=(0.99,0.99), dtype=tf.float32)\n",
        "\n",
        "train = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                               target_size=(150, 150),\n",
        "                               batch_size=256,\n",
        "                               class_mode=\"binary\",\n",
        "                               color_mode=\"rgb\",\n",
        "                               shuffle=True,\n",
        "                               seed=123,\n",
        "                               subset=\"training\")\n",
        "\n",
        "val = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                               target_size=(150, 150),\n",
        "                               batch_size=8,\n",
        "                               class_mode=\"binary\",\n",
        "                               color_mode=\"rgb\",\n",
        "                               shuffle=True,\n",
        "                               seed=123,\n",
        "                               subset=\"validation\")\n",
        "\n",
        "# CNN Model\n",
        "cnn_model = Sequential([\n",
        "    InputLayer(input_shape=(150, 150, 3)),\n",
        "    Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:03.229422Z",
          "iopub.execute_input": "2024-04-24T06:05:03.229702Z",
          "iopub.status.idle": "2024-04-24T06:05:03.983108Z",
          "shell.execute_reply.started": "2024-04-24T06:05:03.229675Z",
          "shell.execute_reply": "2024-04-24T06:05:03.98223Z"
        },
        "trusted": true,
        "id": "xjRA4Lu8CVQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:03.98439Z",
          "iopub.execute_input": "2024-04-24T06:05:03.984661Z",
          "iopub.status.idle": "2024-04-24T06:05:03.990002Z",
          "shell.execute_reply.started": "2024-04-24T06:05:03.984635Z",
          "shell.execute_reply": "2024-04-24T06:05:03.989134Z"
        },
        "trusted": true,
        "id": "VQVqFGtlCVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:03.991428Z",
          "iopub.execute_input": "2024-04-24T06:05:03.991844Z",
          "iopub.status.idle": "2024-04-24T06:05:03.99974Z",
          "shell.execute_reply.started": "2024-04-24T06:05:03.991808Z",
          "shell.execute_reply": "2024-04-24T06:05:03.998861Z"
        },
        "trusted": true,
        "id": "O1LV_HnICVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn_model.compile(optimizer=Adam(0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "cnn_model.summary()\n",
        "\n",
        "# SVM Model\n",
        "svm_model = SVC(kernel='linear', probability=True)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:04.00097Z",
          "iopub.execute_input": "2024-04-24T06:05:04.001236Z",
          "iopub.status.idle": "2024-04-24T06:05:04.018134Z",
          "shell.execute_reply.started": "2024-04-24T06:05:04.00121Z",
          "shell.execute_reply": "2024-04-24T06:05:04.017463Z"
        },
        "trusted": true,
        "id": "7xeZ4r12CVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Transfer Learning Model (using a pre-trained model like VGG16)\n",
        "base_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:04.021271Z",
          "iopub.execute_input": "2024-04-24T06:05:04.021546Z",
          "iopub.status.idle": "2024-04-24T06:05:04.639321Z",
          "shell.execute_reply.started": "2024-04-24T06:05:04.02152Z",
          "shell.execute_reply": "2024-04-24T06:05:04.638483Z"
        },
        "trusted": true,
        "id": "SU5CPIN2CVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Assuming you have defined and trained base_model before this code snippet\n",
        "\n",
        "# Freeze the layers in base_model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define transfer_model\n",
        "transfer_model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile transfer_model\n",
        "transfer_model.compile(optimizer=Adam(0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "transfer_model.summary()\n",
        "\n",
        "# Assuming you have 'train' and 'val' datasets for training and validation\n",
        "\n",
        "# Train transfer_model\n",
        "transfer_history = transfer_model.fit(train, verbose=1, callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5, restore_best_weights=True)], epochs=20, validation_data=val)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = transfer_history.history['val_accuracy'][-1]\n",
        "print(\"Validation Accuracy of the transfer_model:\", accuracy)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:05:04.640885Z",
          "iopub.execute_input": "2024-04-24T06:05:04.641167Z",
          "iopub.status.idle": "2024-04-24T06:17:59.400484Z",
          "shell.execute_reply.started": "2024-04-24T06:05:04.641139Z",
          "shell.execute_reply": "2024-04-24T06:17:59.39953Z"
        },
        "trusted": true,
        "id": "iKvZNdulCVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_transfer.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:17:59.401922Z",
          "iopub.execute_input": "2024-04-24T06:17:59.402288Z",
          "iopub.status.idle": "2024-04-24T06:17:59.604731Z",
          "shell.execute_reply.started": "2024-04-24T06:17:59.40225Z",
          "shell.execute_reply": "2024-04-24T06:17:59.603966Z"
        },
        "trusted": true,
        "id": "Vk7pdOtTCVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset into a DataFrame\n",
        "train_data_path = \"/kaggle/input/brian-tumor-dataset/metadata_rgb_only.csv\"\n",
        "train = pd.read_csv(train_data_path)\n",
        "\n",
        "# Display the column names\n",
        "print(train.columns)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:17:59.606107Z",
          "iopub.execute_input": "2024-04-24T06:17:59.606494Z",
          "iopub.status.idle": "2024-04-24T06:17:59.634091Z",
          "shell.execute_reply.started": "2024-04-24T06:17:59.606453Z",
          "shell.execute_reply": "2024-04-24T06:17:59.633287Z"
        },
        "trusted": true,
        "id": "glcYoupOCVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import dump\n",
        "\n",
        "# Data preparation\n",
        "gen = ImageDataGenerator(rescale=1./255, validation_split=0.2, zoom_range=(0.99, 0.99), dtype=tf.float32)\n",
        "\n",
        "train = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                                target_size=(150, 150),  # Adjusted target size\n",
        "                                batch_size=256,\n",
        "                                class_mode=\"binary\",\n",
        "                                color_mode=\"rgb\",\n",
        "                                shuffle=True,\n",
        "                                seed=123,\n",
        "                                subset=\"training\")\n",
        "\n",
        "val = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                              target_size=(150, 150),  # Adjusted target size\n",
        "                              batch_size=8,\n",
        "                              class_mode=\"binary\",\n",
        "                              color_mode=\"rgb\",\n",
        "                              shuffle=True,\n",
        "                              seed=123,\n",
        "                              subset=\"validation\")\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=50, random_state=123)  # Set n_estimators to a smaller value\n",
        "\n",
        "# Extract features and labels\n",
        "train_features, train_labels = next(train)\n",
        "val_features, val_labels = next(val)\n",
        "\n",
        "# Reshape features for Random Forest\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features = val_features.reshape(val_features.shape[0], -1)\n",
        "\n",
        "# Flatten labels for Random Forest\n",
        "train_labels = train_labels.flatten()\n",
        "val_labels = val_labels.flatten()\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_val_preds = rf_model.predict(val_features)\n",
        "rf_accuracy = accuracy_score(val_labels, rf_val_preds)\n",
        "print(\"Random Forest Model Accuracy:\", rf_accuracy)\n",
        "\n",
        "# Save Random Forest model\n",
        "model_path = '/kaggle/working/random_forest_model.joblib'\n",
        "dump(rf_model, model_path)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:17:59.635108Z",
          "iopub.execute_input": "2024-04-24T06:17:59.635356Z",
          "iopub.status.idle": "2024-04-24T06:18:02.999656Z",
          "shell.execute_reply.started": "2024-04-24T06:17:59.635333Z",
          "shell.execute_reply": "2024-04-24T06:18:02.998743Z"
        },
        "trusted": true,
        "id": "CGpTweQsCVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from joblib import dump\n",
        "\n",
        "# Data preparation\n",
        "gen = ImageDataGenerator(rescale=1./255, validation_split=0.2, zoom_range=(0.99, 0.99), dtype=tf.float32)\n",
        "\n",
        "train = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                                target_size=(150, 150),\n",
        "                                batch_size=256,\n",
        "                                class_mode=\"binary\",\n",
        "                                color_mode=\"rgb\",\n",
        "                                shuffle=True,\n",
        "                                seed=123,\n",
        "                                subset=\"training\")\n",
        "\n",
        "val = gen.flow_from_directory(\"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\",\n",
        "                              target_size=(150, 150),\n",
        "                              batch_size=8,\n",
        "                              class_mode=\"binary\",\n",
        "                              color_mode=\"rgb\",\n",
        "                              shuffle=True,\n",
        "                              seed=123,\n",
        "                              subset=\"validation\")\n",
        "\n",
        "# CNN Model\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding=\"same\", input_shape=(150, 150, 3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding=\"same\"),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer=Adam(0.001), loss=BinaryCrossentropy(), metrics=['accuracy'])\n",
        "cnn_model.summary()\n",
        "\n",
        "# Training with early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "cnn_history = cnn_model.fit(train, epochs=20, validation_data=val, callbacks=[early_stopping])\n",
        "\n",
        "# Saving CNN model\n",
        "cnn_model.save('model_cnn.h5')\n",
        "\n",
        "# Random Forest Model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=123)\n",
        "\n",
        "# Extract features and labels\n",
        "train_features, train_labels = next(train)\n",
        "val_features, val_labels = next(val)\n",
        "\n",
        "# Reshape features for Random Forest\n",
        "train_features = train_features.reshape(train_features.shape[0], -1)\n",
        "val_features = val_features.reshape(val_features.shape[0], -1)\n",
        "\n",
        "# Flatten labels for Random Forest\n",
        "train_labels = train_labels.flatten()\n",
        "val_labels = val_labels.flatten()\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "rf_val_preds = rf_model.predict(val_features)\n",
        "rf_accuracy = accuracy_score(val_labels, rf_val_preds)\n",
        "print(\"Random Forest Model Accuracy:\", rf_accuracy)\n",
        "\n",
        "# Save Random Forest model\n",
        "model_path = '/kaggle/working/random_forest_model.joblib'\n",
        "dump(rf_model, model_path)\n",
        "\n",
        "# Ensemble Model\n",
        "# Load CNN and transfer learning models\n",
        "cnn_model = load_model('model_cnn.h5')\n",
        "transfer_model = load_model('model_transfer.h5')\n",
        "\n",
        "# Generate predictions\n",
        "cnn_preds = cnn_model.predict(val)\n",
        "transfer_preds = (transfer_model.predict(val) > 0.5).astype(\"int32\")\n",
        "rf_preds = rf_model.predict(val_features)\n",
        "\n",
        "# Reshape predictions if necessary\n",
        "if cnn_preds.ndim > 1:\n",
        "    cnn_preds = cnn_preds.flatten()\n",
        "if transfer_preds.ndim > 1:\n",
        "    transfer_preds = transfer_preds.flatten()\n",
        "if rf_preds.ndim > 1:\n",
        "    rf_preds = rf_preds.flatten()\n",
        "\n",
        "# Reshape predictions to match the shape of val_labels\n",
        "max_len = len(val_labels)\n",
        "\n",
        "cnn_preds = np.resize(cnn_preds, max_len)\n",
        "transfer_preds = np.resize(transfer_preds, max_len)\n",
        "rf_preds = np.resize(rf_preds, max_len)\n",
        "\n",
        "# Ensemble predictions\n",
        "ensemble_preds = np.round((cnn_preds + transfer_preds + rf_preds) / 3)\n",
        "ensemble_accuracy = accuracy_score(val_labels, ensemble_preds)\n",
        "print(\"Ensemble Model Accuracy:\", ensemble_accuracy)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:18:03.001162Z",
          "iopub.execute_input": "2024-04-24T06:18:03.001554Z",
          "iopub.status.idle": "2024-04-24T06:30:24.43107Z",
          "shell.execute_reply.started": "2024-04-24T06:18:03.001512Z",
          "shell.execute_reply": "2024-04-24T06:30:24.430173Z"
        },
        "trusted": true,
        "id": "JvfePm_xCVQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.plot(cnn_history.history['accuracy'], label='ensemble_accuracy')\n",
        "plt.plot(cnn_history.history['val_accuracy'], label='val_ensemble_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:30:24.43232Z",
          "iopub.execute_input": "2024-04-24T06:30:24.432623Z",
          "iopub.status.idle": "2024-04-24T06:30:24.594954Z",
          "shell.execute_reply.started": "2024-04-24T06:30:24.432592Z",
          "shell.execute_reply": "2024-04-24T06:30:24.59397Z"
        },
        "trusted": true,
        "id": "0IpPMGo2CVQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cnn_history.history['loss'], label='loss')\n",
        "plt.plot(cnn_history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:30:24.596264Z",
          "iopub.execute_input": "2024-04-24T06:30:24.596623Z",
          "iopub.status.idle": "2024-04-24T06:30:24.757897Z",
          "shell.execute_reply.started": "2024-04-24T06:30:24.596583Z",
          "shell.execute_reply": "2024-04-24T06:30:24.75701Z"
        },
        "trusted": true,
        "id": "u6bd_qkwCVQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Concatenate, Input\n",
        "\n",
        "# Get the output shapes of the CNN and transfer learning models\n",
        "cnn_features = cnn_model.layers[-2].output_shape[1]\n",
        "transfer_features = transfer_model.layers[-2].output_shape[1]\n",
        "\n",
        "# Calculate the total number of features\n",
        "num_features = cnn_features + transfer_features\n",
        "\n",
        "# Create a combined model for ensemble prediction\n",
        "ensemble_input = Input(shape=(num_features,), name='ensemble_input')\n",
        "cnn_output = cnn_model.layers[-2].output  # Get the output of the last dense layer in CNN model\n",
        "transfer_output = transfer_model.layers[-2].output  # Get the output of the last dense layer in transfer learning model\n",
        "\n",
        "# Concatenate the outputs of CNN and transfer learning models with the ensemble input\n",
        "ensemble_output = Concatenate()([cnn_output, transfer_output, ensemble_input])\n",
        "\n",
        "# Add dense layers for final prediction\n",
        "ensemble_output = Dense(128, activation='relu')(ensemble_output)\n",
        "ensemble_output = Dense(1, activation='sigmoid')(ensemble_output)\n",
        "\n",
        "# Define the ensemble model\n",
        "ensemble_model = Model(inputs=[cnn_model.input, transfer_model.input, ensemble_input], outputs=ensemble_output)\n",
        "\n",
        "# Plot the architecture of the ensemble model\n",
        "plot_model(ensemble_model, to_file='ensemble_model.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T06:30:24.759187Z",
          "iopub.execute_input": "2024-04-24T06:30:24.759567Z",
          "iopub.status.idle": "2024-04-24T06:30:25.37894Z",
          "shell.execute_reply.started": "2024-04-24T06:30:24.759527Z",
          "shell.execute_reply": "2024-04-24T06:30:25.377938Z"
        },
        "trusted": true,
        "id": "Mdjy6oHeCVQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next step: Actually create a test set!\n",
        "# This model will be sufficient for this task, so no need for a bigger model."
      ],
      "metadata": {
        "id": "t6hxjiGHCVQd"
      }
    }
  ]
}